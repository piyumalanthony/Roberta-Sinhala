{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8eab8e"
      },
      "source": [
        "# !pip3 install torch"
      ],
      "id": "fe8eab8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ab52939"
      },
      "source": [
        "# !pip3 install tqdm"
      ],
      "id": "3ab52939",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58c09c24"
      },
      "source": [
        "# !pip3 install transformers"
      ],
      "id": "58c09c24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6fb4244",
        "outputId": "5cf99235-e765-4c64-876f-d8187f7ce5b4"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "torch.__version__"
      ],
      "id": "b6fb4244",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.9.1+cu102'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50b7b142"
      },
      "source": [
        "from pathlib import Path\n",
        "paths = [str(x) for x in Path('/userdirs/piyumal/roberta_sinhala/content/sinhala-dataset-creation/datasets/tokenized/').glob('**/*.txt')]"
      ],
      "id": "50b7b142",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a05d11d1",
        "outputId": "4795a29e-090b-4c8b-b34c-df17a039bb60"
      },
      "source": [
        "len(paths)"
      ],
      "id": "a05d11d1",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "158"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ec56499"
      },
      "source": [
        "# from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "# tokenizer = ByteLevelBPETokenizer()"
      ],
      "id": "8ec56499",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "720336f5"
      },
      "source": [
        "# tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2,\n",
        "#                 special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])"
      ],
      "id": "720336f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7b5e5ab"
      },
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('./Roberta_tokenizer')\n",
        "\n",
        "# tokenizer.save_model('Roberta_tokenizer')\n",
        "# tokenizer.save(\"./Roberta_tokenizer/config.json\") \n",
        "# tokenizer.save(\"./Roberta_tokenizer/tokenizer.json\") "
      ],
      "id": "c7b5e5ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbb05b2f",
        "outputId": "f72183c4-55e8-4c25-abc4-dccbb4538bad"
      },
      "source": [
        "from transformers import RobertaTokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('Roberta_tokenizer', max_len=512)"
      ],
      "id": "bbb05b2f",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce8e3e78"
      },
      "source": [
        "tokens = tokenizer(\"එවිට දවසින් දවස අවතැන්වූවන් සිටින කඳවුරුවලට මෙම සෞඛ්‍ය කණ්ඩායම් යවනවා\")"
      ],
      "id": "ce8e3e78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "157ec3a1",
        "outputId": "e2c8d4d6-e78d-49d8-eb13-f60c995da309"
      },
      "source": [
        "print(tokens)"
      ],
      "id": "157ec3a1",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [0, 1056, 265, 280, 599, 265, 266, 264, 599, 1702, 284, 266, 264, 267, 320, 329, 264, 286, 265, 280, 265, 266, 1366, 272, 270, 272, 574, 288, 276, 273, 286, 501, 490, 294, 269, 586, 264, 304, 268, 415, 264, 3476, 268, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9286b0a1"
      },
      "source": [
        "with open('Sinhala_all_data.txt', 'r', encoding='utf-8') as fp:\n",
        "    lines = fp.read().split('\\n')"
      ],
      "id": "9286b0a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb705f74",
        "outputId": "4885ec3b-50a2-4dc4-848f-16e898630b65"
      },
      "source": [
        "lines[:100]"
      ],
      "id": "fb705f74",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " 'ලාල් රූපතුංග රතිඥාවක් පත්තු කිරීමට උත්සහ දරන විට ලියනපතිරණ රතිඤාවක් පත්තු කොට පහත මාලයට විසි කලේය',\n",
              " 'ජනතාව ජන්දයෙන් ප්\\u200dරතික්ෂේප කළ අය ද දැන් ඒ ආණ්ඩුවේ නිලතල දරති',\n",
              " 'ජයවිලාල් විලේගොඩගේ නොපළ ලිපි සුනිල් මිහිඳුකුල පි',\n",
              " 'අධිරාජ්\\u200dයයට ගැති වෙති',\n",
              " 'ප්\\u200dරශ්නෙකට කියල ලොකුවටම ආවෙ එයා පිට රට ඉන්න එයාගෙ යාලුවෙක් කියල කියපු ගර්ල් කෙනෙක් එක්ක ඕනෙවට වඩා කතාකරන්න පටං ගත්ත එක තමයි',\n",
              " 'මමත් එහෙම වෙලා හිටිය නිසා මම අත්දැකීමෙන් දන්නවා ඒදේ',\n",
              " 'ඔයාල කරල තියෙන එකේ එක හරියටම බලාගන්න නම් එකේ කියන තැන බලන්න',\n",
              " 'නීත්\\u200dයනුකූල ව රට යන්න',\n",
              " 'එය ශ්\\u200dරී ලංකාවාසීන්ට නැවුම් අත්දැකීමක් වන්නේ එය මුහුද ගොඩකර ඉදිකෙරුණු නගරයක් නිසාවෙනි',\n",
              " 'ඒ පිළිබඳ නිවේදනද නිකුත් කරයි',\n",
              " 'අප යුක්තිය පුවත්පත පවත්වාගෙන ගිය කාලයේ සිංහල බෞද්ධාගමේ මුදුන්මල්කඩ වන භික්ෂූන් පවා රහමෙරට ආසා කරන බවට නිශ්චිත සාක්ෂි තිබුණි',\n",
              " 'හිටපු ජනාධිපති මහින්ද රාජපක්ෂ මහතාගේ පියා වූ ඩී.ඒ. රාජපක්ෂ මහතාගේ ගුණ සමරු සටහනක් සඳහා මෙසේ පාසල් සිසු සිසුවියන් ගෙන්වා තිබුණි',\n",
              " 'විකට රංගන ශිල්පී පින් පොන් සමාවගත් වීඩියෝව ඉවත් කරගනී',\n",
              " 'තරහා ගන්න එපා මචෝ ලියන්නේ මේ විදියටම තමා වෙන තැන් වලත් ඉස්සර ලිව්වා ඒවායෙත්',\n",
              " 'එක්සත් ජාතික පක්ෂය යනු මෙරට ප්\\u200dරථම දේශපාලන පක්ෂයයි',\n",
              " 'අම්බලංගොඩ ඉඩම්තොට ප්\\u200dරදේශයේදී නිවසක් තුළ අභිරහස් ලෙස මියගිය',\n",
              " 'එවෙලේ කඩපු පැණි කොමඩු 😀',\n",
              " 'කිසිම මනුස්සයො දෙන්නෙක් ගත්තොත් ඒ දෙන්නා සර්ව සමාන නෑ',\n",
              " 'සයිටම් නවත්තන්න නෙමෙයි ඒක රජයට වාසි දායක වෙන විදිහට රජයේ වෛද්\\u200dය විද්\\u200dයාලවල ගුණාත්මක තත්ත්වය දියුණු කරන්න අවශ්\\u200dයය විදිහට මෙහෙයවන්න රජය මැදිහත් විය යුතු හැටි මෙතන ලියැවී නැද්ද',\n",
              " 'කොරියානු භාෂා ප්\\u200dරවීනතා විභාගයට වැඩිම අයදුම්පත් තංගල්ලෙන්',\n",
              " 'කොරියා අර්ධද්වීපය න්\\u200dයෂ්ටික අවිවලින් තොර කලාපයක් බවට පත්කිරීම මෙන්ම උතුරු සහ දකුණු කොරියා රාජ්\\u200dයයන් අතර සාම ගිවිසුමකට එළඹීම ද මෙම සාකච්ඡාවල අරමුණයි',\n",
              " 'එසේම 1 පරාක්\\u200dරමබාහු රජු පරාක්\\u200dරම සමුද්\\u200dරයේ ජලය අඩු නොවී ස්ථාවරව තබා ගැනීම සදහා 1වන අග්බෝ රජු පෙර ඉදිකළ මිනිපේ ඇල වස්ගමු ඔයේ සිට අඹන් ගඟට සම්බන්ධ කරන ලදී ඊට අමතරව අඹන් ගඟේ ශාඛා ගංගාවක් වූ කළු ගඟ හරස් කර අමුණක් බැඳ යෝධයෝ බැඳී ඇලක් මගින් ජලය අඹන් ගඟට යා කරන ලදී මේ සියලු ඇල මාර්ග පැරණියේ තිබු අයුරින් ප්\\u200dරතිසංකරණය කර ඇති නිසා පැරණි හෙලයාගේ විශ්මිත තාක්ෂනය හොඳින් අවධාරණය කරගත හැක අද දක්නට ඇති පරාක්\\u200dරම සමුද්\\u200dරයේ වැව් බැම්මේ දිග සැතපුම් 8 1 2 ක් පමණ වේ වැව් බැම්මේ උස අඩ් 40ක් පමණය වර්ග සැතපුම් 28ක් පමණ වෙල් යායකට මෙයින් ජලය සැපයිම කල හැක මෙම ජලාශය දෙවැනි වන්නේ ගල්ඔය ජලාශයට පමණි වැව් බැම්මේ තැනින් තැන ලේඛන කෙටු ගල් කනුවෙයි සිංහල හෝ සංස්කෘත භාෂාවෙන් පිළිවෙලින් මෙම ගල්කණු දෙපැත්තේ අක්ෂර කොටා ඇත රියන් වලින් සඳහන් කර ඇති මෙම ගල්කණුවල වෙනත් ප්\\u200dරසිද්ධ තැන්වල ඇති වැව් කන්ඩ්වල දිග හා සසදා තිබේ නිදසුන් ලෙස 4 5 ගල් කණු අතර දිග රියන් 3200කි ඒ පදවිය වැවේ වැව් කන්ඩියේ දිගයි 5 6 ගල් කණු අතර දිග රියන් 1700කි ඒ කළා වැවේ වෑ කන්ඩියේ දිගයි මෙයින් පරාක්\\u200dරම සමුද්\\u200dරයේ විශාල බව සිතාගත හැකිය',\n",
              " 'ඔවුහු සිසුන් විසින් ප්\\u200dරාණඇපකරුවන් සේ රඳවා තැබුවේ විද්\\u200dයා පීඨයේ ඉහළ මාලයේ කාමරයක් තුළය',\n",
              " 'කවි හදලා ලස්සනට කියකිය ඔවා අවුස්සන්න යන්න එපා අපායේ යාවි මේක හොදයි',\n",
              " 'අනෙක වන්නේ බැංකු සියල්ලම යුරෝ භාවිතයට පරිගණක ගතකොට ඇති බැවින් ඒවා නැවත සකසන්නට කලක් ගත වීමයි',\n",
              " 'එය ඉට්කා ගිවිසුමේ මූලික අරමුණුවලට පාර කැපීමකි',\n",
              " 'අභ්\\u200dයන්තර හා ජාත්\\u200dයන්තර පීඩනය එහිලා ප\\u200d්\\u200dරමුඛය',\n",
              " 'මෙහි අඟල් 7 ක ප්\\u200dරමාණයෙන් යුතු තිරය 2048 1536 ප්\\u200dරමාණයේ විභේදනයකින් යුක්ත වන අතර ඡායාරූපයක මෙන් වූ පරිපූර්ණ සුපැහැදිලිතාවක් ඔබට ලබාදෙනු ඇත',\n",
              " 'හරි හරි ඔය පිස්සු යක්කු ගැන මදැයි දැං',\n",
              " 'ඒ නිසාම තමයි මම හිතුවේ නිරූපිකාවකට වඩා නිළියක් විදිහට මගේ රසිකයන්ට ළං වෙන්න තියෙනවා නම් හොඳයි කියලා',\n",
              " 'එදින ජනාධිපතිවරණයක් මෙන් ම අගමැතිවරණයක් ද පැවැත් වූ බව රනිල් අපට කියා දෙයි',\n",
              " 'ලොකූගේ හොර කේස් එකක්වත් ඩයිනමයිට් එක මාට්ටු කරන්න යනවාද දන්නේ නෑ',\n",
              " 'ජොබ් එක නැති වුනු එක මට නම් සිද්ද වුනු ලොකුම හොඳක්',\n",
              " 'මීට අමතරව පස්වන ශ්\\u200dරේණිය ශිෂ්\\u200dයත්ව විභාගයේ ප්\\u200dරතිඵල පදනම් කරගනිමින් තරගකාරීත්වය ප්\\u200dරවර්ධනය වන අයුරින් පෝස්ටර් බැනර් වැනි ප්\\u200dරචාරක කටයුතු නොකළ යුතු බවද මෙම චක්\\u200dර ලේඛයෙන් අවධාරණය කර තිබේ',\n",
              " 'බයිට් එකකටනම් එලම එල',\n",
              " 'ජාතිවාදී නොවෙන සුලු ජාතීන් 75 80 ප්\\u200dරතිශත වලින් එක පැත්තකට චන්දෙ දෙනවා',\n",
              " 'නැති වෙන්න දෙයකුත් තිබුනේ නැහැයි කියලත් ඔබට යෝජනා කරන්න පුළුවන්',\n",
              " '20යි 20 නායක පිතිකරු',\n",
              " 'ඕනේ වෙලාවට රීස්ටෝ කරගන්න',\n",
              " 'මන්ද තුවක්කුවේ ඉදිරිපස ඇති අල්ලගන්නා කොටස පිටුපසට හා ඉදිරියට චලනය කිරීමේදී පෙර වාරයේදී වෙඩි තැබීමට භාවිතාකල පතරොම ඉවත් කිරීම',\n",
              " 'ආදායම් තත්ත්වය වර්ධනය වීම නිසා යහපත් ආයෝජන කෙරෙහි ඔබගේ අවධානය යොමු වෙයි',\n",
              " 'ඒත් එය නීතියට විරුද්ධ නැති නිසා ඔවුන්ට කිසිවක් කිරීමට බැරි වුනා',\n",
              " 'මේ දවස් වල හුගක් අය කතා වෙන දෙයක්නෙ අලුත් සංස්කරණය කියන්නෙ',\n",
              " 'එක එකාට කාඩ් ගැහුවට උඹේ කාඩ් කුඩු',\n",
              " 'මම හැමෝටම කියන්න කැමතියි ශ්\\u200dරී ලංකා යුද හමුදාව මෙම ප්\\u200dරදේශයන්හි කටයුතු කරන්නේ සැහෙන කාලයක ඉඳන් යාපනයේ කොටුව ඇතුළත යුද හමුදාව ඉන්න ප්\\u200dරථම අවස්ථාව මෙයම නෙමෙයි',\n",
              " 'එදා හමුදාපති වූ සරත් ෙන්සේකා පවා පසුව පැවසුවේ යුද්ධයේ අවසාන සමයේ කොටි හමුදාවට බාර වීමට වුවමනා බවට කිසිදු තොරතුරක් තමන්ට නොලැබුණු බවයි.',\n",
              " 'එහෙත් අර්ථ නිරූපණ ආඥා පනතේ 2 වන වගන්තිය අනුව සළකුණකින් අත්සන් කළ හැකි බව දැක්\\u200d\\u200dවෙයි',\n",
              " 'පොන්සේකා කියන්නේ ප්\\u200dරතිපත්තියක් ඇති මිනිහෙක් නෙවෙයි',\n",
              " 'ඒක වෙන්න ඇති ඔය කියන වෙනස',\n",
              " 'කොළඹ අද කැදවා තිබූ මාධ්\\u200dය හමුවකට එක්වෙමින් එහි කැදවුම්කරු ලහිරු වීරසේකර මේ බව සදහන් කළා',\n",
              " 'කාශ්\\u200dයප රජතුමා පසු බහිනවා කියලා හිතපු සේනාව සී සී කඩ දිව්වලු',\n",
              " 'ඒක නිසා බේරෙන එක ගොඩක් අමාරුයි',\n",
              " 'අපි උතුරට ගිහින් ඒක කිව්වා',\n",
              " 'බස් රථය පෙරලීමෙන් නිවසේ වහලට ද දැඩි අලාභ හානි සිදුව ඇති අතර බණ්ඩාරවෙල පොලිසිය වැඩිදුර පරීක්ෂණ පවත්වනවා',\n",
              " 'ජොන් හ්යොන් ජෝ ජූන් ලෙස',\n",
              " 'රුධිර පීඩනයේ බලපෑම නිසා රුධිර නාල සිහින් වන බවත් ඒ නිසා ඇස් අන්ධවීමට පවා බොහෝ දුරට ඉඩ ප්\\u200dරස්ථාව ඇති බවත් සොයාගෙන ඇත',\n",
              " 'මේ ආකාරයට මේ නව ලිබරල්වාදී ව්\\u200dයාපෘතියට ඉදිරියට යන්න දුන්නොත් මේ රටේ ස්වදේශික ජනතාව මේ රට ගිලගන්න ආපු විදේශික සමාගම් ඉදිරියේ අසරණ වේවි',\n",
              " 'අන්න ඒ නිසාමයි මම උඹගැන ඇලර්ට් එකේ ඉදගන අද උඹ එක්ක සෙට්වුනේ',\n",
              " 'ඔහු කියපු දේ මට තාම දෝන්කාර දෙනවා',\n",
              " 'මනුම්\\u200dයය මතක තියාගනින් උඹට ඩොක්ටර් කියලා කියන්නෙ ආචාර්ය කියන අදහසින්',\n",
              " 'කොල්ලගෙ අම්මට තමයි ඊයේ රාත්තිරියෙ සුදු රෙද්දක් පෙරව ගත්ත මියගිය පරාන කාරයෙක් හීනෙන් පෙනිල කියල තියෙන්නෙ',\n",
              " 'එ කොල්ලා පස්සේ දැනගත්තේ නැද්ද දුන්න ලණුව.',\n",
              " 'වෙලාවක් හදාගෙන යමු දවසක',\n",
              " 'ගතවු සතියේ දේශපාලන වේදිකාවේ පළ වූ රසවත් අදහස් රැගත් රස කතා විශේෂාංගය තුළින් අද ඔබ වෙත ගෙන එන්නේ විපක්ෂ නායක රනිල් වික\\u200d්\\u200dරමසිංහ අමාත්\\u200dය කුමාර වෙල්ගම හා පාර්ලිමේන්තු මන්ත\\u200d්\\u200dරී හරීන් ප\\u200d්\\u200dරනාන්දු දේශපාලන වේදිකාවේ දැක්වූ අදහස්',\n",
              " 'ඇත්තටම පින් හතේ වැඩක් කරලා තියෙන්නෙ',\n",
              " 'එදා මෙදා තුර ලෝ ප\\u200d්\\u200dර\\u200d්\\u200dරකටවූ නාට්\\u200dය රැසක් ඒවා මුලින්ම කරලිගත වනවිට වාරණයන්ට ලක්ව ඇත',\n",
              " 'ඔන්න මම උණු උණුවෙම ගත්තා',\n",
              " 'ටෙලි නාට්\\u200dයවලට වගේම දේශපාලනයටත් ඒ කාලෙ ඉඳන්ම ආරාධනා ලැබුණා',\n",
              " 'කොළඹ වරායට පිවිසීමේ දී මෙතෙක් අය කල ගාස්තුව සියයට 4000 කින් ඉහළ නැංවීමට එරෙහිව හෙට සිට වෘත්තීය ක්\\u200dරියාමාර්ගයක නිරතවන බව වරාය භාවිතා කරන්නන්ගේ සංගම් එකමුතුව ප්\\u200dරකාශ කළා',\n",
              " 'ඉන්පසු තවදුරටත් කටයුතු කරගෙන යාම ඔබ හා එකී පාර්ශවන්ගේ උවමනාව කැමැත්ත හා එකඟතාවය මත පමණක් සිදුවේ',\n",
              " 'එහෙත් දැන් ඉන් එක විශේෂයක් හැර අනෙක් විශේෂ සියල්ල නෂ්ටප\\u200d්\\u200dරාප්තය',\n",
              " 'නැනෝ තාක්ෂනය පිළිබද ඇති විශේෂ පිටු වලින් කොටසක්',\n",
              " 'මම කතාවට කෙළින්ම එන්නම්',\n",
              " 'මම මෙච්චර කල් හිතන් හිටියෙ සිරස ඒ ළමයින්ව ගිවිසුම් වල සිර කරගෙන හම්බ කරනව කියල',\n",
              " 'ඉතින් මං කියන්න හැදුවෙ අපි අවුරුදු ගණන් ගෙවල ලොකු වයසකට එද්දි අපිව හතරැස් රාමුවකට කොටු වෙනව.එක්කො කොටු කරනව.ගෙදර වටපිටාවෙන් ගෙදරින් එපිට සමාජයෙන්',\n",
              " 'එම නිෂ්පාදන භාවිතයෙන් විවිධාකාර සෞඛ්\\u200dය ගැටළු මතුවන අතර මුඛ පිළිකා ගලනාලයේ පිළිකා මානසික රෝග හා බඩවැල් ආශ්\\u200dරිත රෝග ඇතිවන බව අනාවරණ වී තිබේ',\n",
              " 'බොහෝ විට අදාල විෂය භාර ඇමති හෝ වෙනත් රාජ්\\u200dය අධිකාරියක් විසිනුයි රෙගුලාසි පනවන්නේ',\n",
              " 'මුල ඉඳල කියවන්න ගත්ත',\n",
              " 'මෙම ගුවන් යානය මත්තල ජාත්\\u200dයන්තර ගුවන්තොටුපලට ගොඩ බැස්සවීමෙන් රුපියල් මිලියන 15 ක ආදායමක් ලැබුණු බවයි ගුවන් තොටුපළ කළමණාකරු උපුල් කලංසූරිය හිරු ප්\\u200dරවෘත්ති අංශයට කියා සිටියේ',\n",
              " 'රටම හිනැස්සූ ප්\\u200dරවීණ රංගන ශිල්පී සුනිල් හෙට්ටි ආරච',\n",
              " 'මේකේ දැන් තිර රචනයක් නෑනේ',\n",
              " 'සං වරා පිරිසුදුව ශුද්ධ කර ගත හැකි බවත් දැකිය යුතුයි',\n",
              " 'මෙහිදී ශ්\\u200dරී ලංකා ඉනිම ගොඩනැගීම වෙනුවෙන් කැපී පෙනෙන දායකත්වයක් ලබා දුන් භානුක රාජපක්ෂ පන්දු 48කට මුහුණ ද\\u200dෙමින් අගනා ලකුණු 77ක් රැස් කිරීමට සමත් විය',\n",
              " 'දි මු අස්නොකර ම මෛත්\\u200dරිපාල රනිල් අගමැති ලෙස පත් කළා',\n",
              " 'දැන් නම් නමයට විතර නවතිනවා',\n",
              " 'ඔය අතරේ පෙන්දිට ට්\\u200dරයි කරපු කොල්ලත් උණුහුම',\n",
              " 'මෙතන මොකේක් හරි මගේ අයියට පාර්ට් එකක් එහෙම දාලා තිබ්බොත් බලාගන්න පුළුවන් හරිය',\n",
              " '1993 පුනගරින් කඳවුර විමුක්ති කොටි විසින් අත්පත් කරගන්නා ලදි',\n",
              " 'අන්තර් සමාජ පළමු කොටසේ විස්සයි20 තරගාවලියේදී ශතක දෙකක් රැුස්කළ දසුන් ශානක සංචිතයට කැදවා සිටියද ඉකුත් අගහරුවාදා ආරම්භ වූ අන්තර් කලාප වි',\n",
              " 'නිකමට හිතන්න විමල් වීරවංශ කීවාක් මෙන් රාත්\\u200dරී නිදන්නට යන විට ඔබේ දරුවන් මාතු පාදන් නමාමී යන්න සොප්\\u200dරාණෝ ක්\\u200dරමයට කිව්වොත් කොහොමට හිටීද',\n",
              " 'ඉදිරිපත් කරනු ලැබූ මෙම ලිපියෙන් අතේ ඇගිලි අතර ඇති පරතරය විමසා බලා පුද්ගලයෙකුගේ චරිත ස්වභාවය විශ්ලේෂණය කරන ආකාරය ඔබ දැනගන්නට ඇති කියා අප සිතනවා',\n",
              " 'කැරම් බෝඞ් ආනයනය කිරීමකදී රුපියල් මිලියන ගණනක වංචාවක් සිදුව ඇති බවටයි ඔහුට චෝදනා එල්ල වී ඇත්තේ',\n",
              " 'මේ ථුපයේ විෂ්කම්භය අඩි 370කි',\n",
              " 'ඒකයි වෙනස අපි දෙන්නගෙ අදහස් දෙකේ.',\n",
              " 'කුලපීඩනයට එරෙහිව ඉන්දියාවේ මායාවතීලා බුදු දහම වැළඳගැනීමට සැරසෙද්දී',\n",
              " 'මේක ඇත්තටම මානව අයිතිවාසිකම් උල්ලගන්ය කිරීමක්',\n",
              " 'එකෙක් නහයෙ ඇගිල්ල ගහලා අනිකාට පෙන්නනවා මේ කියලා',\n",
              " 'මේ නිසා එකක් තෝරා ගන්න',\n",
              " 'නමුත් පිරිසිඳු කෘතිම දියමන්ති ඉතා ඉහළ තාප සන්නායක වනමුත් නොසැලකියහැකි තරම් කුඩා විද්\\u200dයුත් සන්නායකතාවක් දරයි']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "238ca5d3",
        "outputId": "104efb4e-94a3-4dfc-e736-e0eeec3e93de"
      },
      "source": [
        "len(lines)"
      ],
      "id": "238ca5d3",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15790635"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0afee9a2"
      },
      "source": [
        "def mlm(input_ids):\n",
        "    # input_ids = labels.detach().clone()\n",
        "    # create random array of floats with equal dims to input_ids\n",
        "    rand = torch.rand(input_ids.shape)\n",
        "    # mask random 15% where token is not 0 [PAD], 1 [CLS], or 2 [SEP]\n",
        "    mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 1) * (input_ids != 2)\n",
        "    # loop through each row in input_ids tensor (cannot do in parallel)\n",
        "    for i in range(input_ids.shape[0]):\n",
        "        # get indices of mask positions from mask array\n",
        "        # print(\"mask array shape:\", mask_arr.shape)\n",
        "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
        "        # print(\"selection array shape:\", selection)\n",
        "        # mask input_ids\n",
        "        input_ids[i, selection] = 4 \n",
        "    return input_ids"
      ],
      "id": "0afee9a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ecb82d"
      },
      "source": [
        "import torch\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        # store encodings internally\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        # return the number of samples\n",
        "        return self.encodings['input_ids'].shape[0]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # return dictionary of input_ids, attention_mask, and labels for index i\n",
        "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
      ],
      "id": "11ecb82d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2564316"
      },
      "source": [
        "# batch = tokenizer(lines[:100_000], max_length=512, padding='max_length', truncation=True)\n",
        "# len(batch)"
      ],
      "id": "b2564316",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68e29174"
      },
      "source": [
        "# # make copy of labels tensor, this will be input_ids\n",
        "# input_ids = labels.detach().clone()\n",
        "# # create random array of floats with equal dims to input_ids\n",
        "# rand = torch.rand(input_ids.shape)\n",
        "# # mask random 15% where token is not 0 [PAD], 1 [CLS], or 2 [SEP]\n",
        "# mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 1) * (input_ids != 2)\n",
        "# # loop through each row in input_ids tensor (cannot do in parallel)\n",
        "# for i in range(input_ids.shape[0]):\n",
        "#     # get indices of mask positions from mask array\n",
        "#     print(\"mask array shape:\", mask_arr.shape)\n",
        "#     selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
        "#     print(\"selection array shape:\", selection)\n",
        "#     # mask input_ids\n",
        "#     input_ids[i, selection] = 4  # our custom [MASK] token == 3"
      ],
      "id": "68e29174",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "494cdd92"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,  # we align this to the tokenizer vocab_size\n",
        "    max_position_embeddings=514,\n",
        "    hidden_size=768,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=12,\n",
        "    type_vocab_size=1\n",
        ")"
      ],
      "id": "494cdd92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26b71d1"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config)"
      ],
      "id": "c26b71d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af3101ba",
        "outputId": "1bf6edb3-2db2-41b9-ca87-3fc659c251d7"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# and move our model over to the selected device\n",
        "model.to(device)"
      ],
      "id": "af3101ba",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForMaskedLM(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (decoder): Linear(in_features=768, out_features=52000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f863935e"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# activate training mode\n",
        "model.train()\n",
        "# initialize optimizer\n",
        "optim = AdamW(model.parameters(), lr=1e-4)"
      ],
      "id": "f863935e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39013ffa",
        "outputId": "5cd0b029-0d00-4a0b-9221-435fa61e61a4",
        "colab": {
          "referenced_widgets": [
            "edef190efc0c41c7a626bd213bc34e35"
          ]
        }
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "epochs = 1\n",
        "loss_values = []\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, len(lines), 5_00_000):\n",
        "        if i == (len(lines)//5_00_000)*5_00_000:\n",
        "            batch_data = tokenizer(lines[i:], max_length=512, padding='max_length', truncation=True)\n",
        "        else:\n",
        "            batch_data = tokenizer(lines[i:i+5_00_000], max_length=512, padding='max_length', truncation=True)\n",
        "        labels_all = torch.tensor(batch_data.input_ids)\n",
        "        mask_all = torch.tensor(batch_data.attention_mask)\n",
        "        input_ids_all = mlm(labels_all.detach().clone())\n",
        "        encodings = {'input_ids': input_ids_all, 'attention_mask': mask_all, 'labels': labels_all}\n",
        "        dataset = Dataset(encodings)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "    # setup loop with TQDM and dataloader\n",
        "        loop = tqdm(loader, leave=True)\n",
        "        for batch in loop:\n",
        "            # initialize calculated gradients (from prev step)\n",
        "            optim.zero_grad()\n",
        "            # pull all tensor batches required for training\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            # process\n",
        "            outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                            labels=labels)\n",
        "            # extract loss\n",
        "            loss = outputs.loss\n",
        "            # calculate loss for every parameter that needs grad update\n",
        "            loss.backward()\n",
        "            # update parameters\n",
        "            optim.step()\n",
        "            # print relevant info to progress bar\n",
        "            loop.set_description(f'Epoch: {epoch} Text Loading Iter: {i//5_00_000}')\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "            loss_values.append(loss.item())\n",
        "            del input_ids\n",
        "            del attention_mask\n",
        "            del labels\n",
        "        else:\n",
        "            model.save_pretrained(f'./Roberta_models/roberta_model_{epoch}_{i}')\n",
        "            del batch_data\n",
        "            del labels_all \n",
        "            del mask_all \n",
        "            del input_ids_all\n",
        "            gc.collect()\n",
        "            with open('loss_value_file', 'wb') as fp:\n",
        "                pickle.dump(loss_values, fp)"
      ],
      "id": "39013ffa",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edef190efc0c41c7a626bd213bc34e35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/31250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1005481/1894666089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./Roberta_models/roberta_model_{epoch}_{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m# torch.cuda.empty_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#         if i%1_000_000 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/roberta_sinhala/rpt_env/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, save_config, state_dict, save_function, push_to_hub, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;31m# If we save using the predefined names, we can load using `from_pretrained`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0moutput_model_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model weights saved in {output_model_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/roberta_sinhala/rpt_env/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/roberta_sinhala/rpt_env/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77c0696a"
      },
      "source": [
        "# model.save_pretrained('./Test_on_the_way_bert')"
      ],
      "id": "77c0696a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f386e941"
      },
      "source": [
        "from transformers import pipeline\n",
        "fill = pipeline('fill-mask', model='Test_on_the_way_bert', tokenizer=tokenizer)"
      ],
      "id": "f386e941",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "514dfcd1"
      },
      "source": [
        "fill(f'මමත් එහෙම වෙලා හිටිය නිසා {fill.tokenizer.mask_token} අත්දැකීමෙන් දන්නවා ඒද?')"
      ],
      "id": "514dfcd1",
      "execution_count": null,
      "outputs": []
    }
  ]
}